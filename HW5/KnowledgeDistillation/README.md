# KnowledgeDistillation ðŸ“˜

## Overview
Knowledge distillation using contrastive learning between teacher and student models.

## Workflow
1. Define teacher and student networks
2. Apply contrastive learning objective
3. Train student model to mimic teacher
4. Evaluate distillation performance

## Key Concepts
- KnowledgeDistillation
