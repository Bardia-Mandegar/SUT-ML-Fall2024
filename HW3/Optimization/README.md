# Optimization ðŸ“˜

## Overview
Applying optimization techniques (SGD, Momentum, RMSProp, Adam) to train a neural network on MNIST.

## Workflow
1. Load and preprocess MNIST dataset
2. Implement simple neural network
3. Apply optimizers (SGD, Momentum, RMSProp, Adam)
4. Evaluate performance across optimizers

## Key Concepts
- Optimization MNIST
